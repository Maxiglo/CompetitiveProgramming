{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximeGloesener/CompetitiveProgramming/blob/main/Challenge1TestData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK6fZUXolwPs"
      },
      "source": [
        "# **1. Hardware Informations (GPU)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UEjh8Rulquq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df363cc-12a3-46de-a4a1-423434512406"
      },
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  9 12:05:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ImageHash"
      ],
      "metadata": {
        "id": "uqK0POsY1lmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtS3fRhb5x6"
      },
      "source": [
        "# **2. Import des librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS3XuLGyb5x_"
      },
      "source": [
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "import imagehash\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6HqNeyYKraU"
      },
      "source": [
        "#**3.Téléchargement des jeux de données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CwAmMbqmGhW"
      },
      "source": [
        "bases_path_after=\"bases\"\n",
        "test=\"test_data\"\n",
        "if os.path.exists(bases_path_after) == False:\n",
        "    os.makedirs(bases_path_after)\n",
        "if not os.path.exists(test):\n",
        "  os.makedirs(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zdwkyRtmnN-"
      },
      "source": [
        "!rm -rf FIRE_DATABASE_1.tar\n",
        "!rm -rf sample_data\n",
        "!wget https://cluster.ig.umons.ac.be/HackIA21/databases/FIRE_DATABASE_1.tar\n",
        "!tar xf FIRE_DATABASE_1.tar -C 'bases' --one-top-level\n",
        "!rm FIRE_DATABASE_1.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf FIRE_DATABASE_2.tar\n",
        "!rm -rf sample_data\n",
        "!wget https://cluster.ig.umons.ac.be/HackIA21/databases/FIRE_DATABASE_2.tar\n",
        "!tar xf FIRE_DATABASE_2.tar -C 'bases' --one-top-level\n",
        "!rm FIRE_DATABASE_2.tar"
      ],
      "metadata": {
        "id": "e4aYRc5rluNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf FIRE_DATABASE_3.tar\n",
        "!rm -rf sample_data\n",
        "!wget https://cluster.ig.umons.ac.be/HackIA21/databases/FIRE_DATABASE_3.tar\n",
        "!tar xf FIRE_DATABASE_3.tar -C 'bases' --one-top-level\n",
        "!rm FIRE_DATABASE_3.tar"
      ],
      "metadata": {
        "id": "WMfYa9uIluzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "! wget --no-check-certificate https://download.smartappli.eu/small.tar\n",
        "! tar xf small.tar -C 'bases' --one-top-level\n",
        "! rm small.tar"
      ],
      "metadata": {
        "id": "BbNN3LdwDHCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "! wget --no-check-certificate https://download.smartappli.eu/medium.tar\n",
        "! tar xf medium.tar -C 'bases' --one-top-level\n",
        "! rm medium.tar"
      ],
      "metadata": {
        "id": "Ax1-FdGpDFU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data\n",
        "! wget --no-check-certificate https://download.smartappli.eu/big.tar\n",
        "! tar xf big.tar -C 'bases' --one-top-level\n",
        "! rm big.tar"
      ],
      "metadata": {
        "id": "HOqq2Z6bCXBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Merge tous les jeux de données ensembles**"
      ],
      "metadata": {
        "id": "MUtSR1OxPbv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -a /content/bases/FIRE_DATABASE_1/no_fire//. /content/bases/big/no_fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_2/no_fire/. /content/bases/big/no_fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_3/no_fire/. /content/bases/big/no_fire/\n",
        "!cp -a /content/bases/medium/no_fire/. /content/bases/big/no_fire/\n",
        "!cp -a /content/bases/small/no_fire/. /content/bases/big/no_fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_1/start_fire/. /content/bases/big/start_fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_2/start_fire/. /content/bases/big/start_fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_3/start_fire/. /content/bases/big/start_fire/\n",
        "!cp -a /content/bases/medium/start_fire/. /content/bases/big/start_fire/\n",
        "!cp -a /content/bases/small/start_fire/. /content/bases/big/start_fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_1/fire/. /content/bases/big/fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_2/fire/. /content/bases/big/fire/\n",
        "!cp -a /content/bases/FIRE_DATABASE_3/fire/. /content/bases/big/fire/\n",
        "!cp -a /content/bases/medium/fire/. /content/bases/big/fire/\n",
        "!cp -a /content/bases/small/fire/. /content/bases/big/fire/"
      ],
      "metadata": {
        "id": "SnmsaePRM_Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre d'images après avoir tout merge\n",
        "len(os.listdir(\"/content/bases/big/fire\"))+len(os.listdir(\"/content/bases/big/no_fire\"))+len(os.listdir(\"/content/bases/big/start_fire\"))"
      ],
      "metadata": {
        "id": "4pIfqYYIS32O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Données de test\n",
        "!rm -rf sample_data\n",
        "!wget --no-check-certificate https://download.smartappli.eu/test.tar\n",
        "! tar xf test.tar -C 'test_data' --one-top-level\n",
        "! rm test.tar"
      ],
      "metadata": {
        "id": "Us_JlUVUXamR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bab152-11b3-4163-eab0-e5d3a238d49f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-09 12:04:35--  https://download.smartappli.eu/test.tar\n",
            "Resolving download.smartappli.eu (download.smartappli.eu)... 46.105.57.169, 2001:41d0:301::20\n",
            "Connecting to download.smartappli.eu (download.smartappli.eu)|46.105.57.169|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58196992 (56M) [application/x-tar]\n",
            "Saving to: ‘test.tar’\n",
            "\n",
            "test.tar            100%[===================>]  55.50M  19.8MB/s    in 2.8s    \n",
            "\n",
            "2022-11-09 12:04:38 (19.8 MB/s) - ‘test.tar’ saved [58196992/58196992]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important de tester les doublons en utilisant un hash cryptographique qui comparer les images pixels par pixels. Avec un hash robuste, on trouve des faux doublons. Le hash robuste permet de détecter les doublons si resize/légère modifiction mais ce n'est pas le cas ici dans les datasets. "
      ],
      "metadata": {
        "id": "prGdb9QW88gL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Analyse du dataset**"
      ],
      "metadata": {
        "id": "LI2bWVshP0Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(file_name):\n",
        "  \"\"\"\n",
        "  Fonction qui prend en entrée une path d'image et qui return RGB (utile pour plot)\n",
        "  \"\"\"\n",
        "  img = cv2.imread(file_name, 3)\n",
        "  b,g,r = cv2.split(img)\n",
        "  rgb_image = cv2.merge([r,g,b])\n",
        "  return rgb_image\n",
        "\n",
        "def plot(images, noms):\n",
        "  f, axarr = plt.subplots(1,len(images))\n",
        "  for i in range(len(images)):\n",
        "    axarr[i].imshow(images[i])\n",
        "    axarr[i].title.set_text(noms[i])\n"
      ],
      "metadata": {
        "id": "-T0WHM1aQShA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse des données\n",
        "# On sait que dans les datasets, il y a parfois plusieurs fois la même image\n",
        "# But : analyser chaque dataset et trouver le nombre d'images en doublons\n",
        "def analyse_dataset(folder_name, affichage = False):\n",
        "  \"\"\"\n",
        "  Fonction qui prend en entrée le directory d'un dataset et qui va chercher les images qui sont présentes plusieurs fois pour ce même dataset\n",
        "  Affichage = True si on veut plot les images qui sont en doubles et leur nom\n",
        "  Return: - le nombre de doublons dans un dataset\n",
        "          - le pourcentage de doublons\n",
        "  \"\"\"\n",
        "  img_hashes = dict()\n",
        "  total = 0\n",
        "  doublons = 0\n",
        "\n",
        "  for dir in os.listdir(folder_name):\n",
        "    for image in os.listdir(os.path.join(folder_name, dir)):\n",
        "      total += 1\n",
        "      image = os.path.join(os.getcwd(), folder_name, dir, image)\n",
        "      hash = imagehash.dhash(Image.open(image))\n",
        "      if hash in img_hashes:\n",
        "        doublons += 1\n",
        "        #print(f'{image} doublons de {img_hashes[hash]}')\n",
        "        if affichage:\n",
        "          i = read_image(image) \n",
        "          x = read_image(img_hashes[hash])\n",
        "          plot([x,i],[image.split(\"/\")[-1], img_hashes[hash].split(\"/\")[-1]])\n",
        "      else:\n",
        "        img_hashes[hash] = image\n",
        "\n",
        "  return doublons, doublons/total*100\n",
        "\n",
        "\n",
        "d2, p2 = analyse_dataset(\"/content/bases/big/\")\n",
        "\n",
        "\n",
        "print(f'Il y a {d2} doublons dans le dataset = {p2}% des données')\n"
      ],
      "metadata": {
        "id": "tIpQq5lygtsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Suppression des doublons**"
      ],
      "metadata": {
        "id": "vF3vhn5AP7I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['fire/', 'start_fire/', 'no_fire/']\n",
        "\n",
        "hash_dict = {}\n",
        "directory_path = \"/content/bases/big/\" \n",
        "for classe in classes:\n",
        "\n",
        "  path = os.path.join(directory_path, classe)\n",
        "\n",
        "  for image in (os.listdir(path)):\n",
        "\n",
        "    path_image = path + image\n",
        "\n",
        "    hash = imagehash.dhash(Image.open(path_image))\n",
        "\n",
        "    if hash not in hash_dict:\n",
        "      hash_dict[hash] = path_image\n",
        "\n",
        "    else:\n",
        "      #print(f'{hash_dict[hash]} is equal to {path_image}')\n",
        "      os.remove(path_image)\n",
        "      #print(f'{path_image} removed')"
      ],
      "metadata": {
        "id": "hCre90rQNZRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taille après suppression des doublons\n",
        "len(os.listdir(\"/content/bases/big/fire\"))+len(os.listdir(\"/content/bases/big/no_fire\"))+len(os.listdir(\"/content/bases/big/start_fire\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7drB8uuNlfZ",
        "outputId": "b0b1680d-8bcf-44a3-dd22-5561fedeb553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6453"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Import des données sur le drive**"
      ],
      "metadata": {
        "id": "jmtm395EQDNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ90nY8gNots",
        "outputId": "b586b5f5-3959-44cd-fac4-f5cb2cfaeb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -av '/content/bases/big/' '/content/gdrive/MyDrive/Challenge1/'"
      ],
      "metadata": {
        "id": "TkouDctoNrjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -av '/content/test_data/' '/content/gdrive/MyDrive/Challenge1/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APvKewE0QJeO",
        "outputId": "b28df532-c8ac-4781-872f-d056a6cc31d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/test_data/' -> '/content/gdrive/MyDrive/Challenge1/test_data/test_data'\n"
          ]
        }
      ]
    }
  ]
}